artifacts:
  ARTIFACTS_DIR: artifacts
  DATA_DIR: artifacts/data
  RETRIEVER_DIR: artifacts/retriever
  READER_DIR: artifacts/reader
  INDEX_DIR: artifacts/index

data:
  # Primary dataset – change later to your own benchmark
  dataset_name: ccdv/govreport-summarization # allenai/booksum
  dataset_config: null # default
  dataset_split: train[:100]   # Small for testing – change to train/validation later
  max_samples: null
  max_input_length: 100000
  chunk_size: 512
  chunk_overlap: 64
  top_k: 32

retriever:
  model_name: BAAI/bge-large-en-v1.5
  device: cuda
  batch_size: 32

reader:
  base_model: meta-llama/Meta-Llama-3.1-8B-Instruct
  lora_r: 64
  lora_alpha: 16
  target_modules: ["q_proj", "v_proj"]
  max_seq_length: 32768
  use_4bit: true
  use_gradient_checkpointing: true
